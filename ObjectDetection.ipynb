{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"yolo.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageAI in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (2.1.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from imageAI) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from imageAI) (1.23.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from imageAI) (3.7.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from imageAI) (3.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from imageAI) (1.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->imageAI) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->imageAI) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->imageAI) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->imageAI) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->imageAI) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->imageAI) (4.33.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->imageAI) (1.16.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\seedevice\\anaconda3\\envs\\myenv\\lib\\site-packages (1.23.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install imageAI\n",
    "! pip install opencv-python\n",
    "! pip install Pillow\n",
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Seedevice\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "obj_detect = ObjectDetection()\n",
    "obj_detect.setModelTypeAsYOLOv3()\n",
    "obj_detect.setModelPath(\"../Object-Detection-with-Python-YOLO/yolo.h5\")\n",
    "obj_detect.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Seedevice\\SanghyunRyu\\Object-Detection-with-Python-YOLO\\ObjectDetection.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Seedevice/SanghyunRyu/Object-Detection-with-Python-YOLO/ObjectDetection.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     annotated_image, preds \u001b[39m=\u001b[39m obj_detect\u001b[39m.\u001b[39mdetectObjectsFromImage(input_image\u001b[39m=\u001b[39mimg,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seedevice/SanghyunRyu/Object-Detection-with-Python-YOLO/ObjectDetection.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                     input_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seedevice/SanghyunRyu/Object-Detection-with-Python-YOLO/ObjectDetection.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                       output_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seedevice/SanghyunRyu/Object-Detection-with-Python-YOLO/ObjectDetection.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                       display_percentage_probability\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seedevice/SanghyunRyu/Object-Detection-with-Python-YOLO/ObjectDetection.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                       display_object_name\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seedevice/SanghyunRyu/Object-Detection-with-Python-YOLO/ObjectDetection.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, annotated_image)     \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Seedevice/SanghyunRyu/Object-Detection-with-Python-YOLO/ObjectDetection.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m (cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mq\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mor\u001b[39;00m (cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m)\u001b[39m==\u001b[39m\u001b[39m27\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seedevice/SanghyunRyu/Object-Detection-with-Python-YOLO/ObjectDetection.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seedevice/SanghyunRyu/Object-Detection-with-Python-YOLO/ObjectDetection.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m cam_feed\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cam_feed = cv2.VideoCapture(0)\n",
    "cam_feed.set(cv2.CAP_PROP_FRAME_WIDTH, 650)\n",
    "cam_feed.set(cv2.CAP_PROP_FRAME_HEIGHT, 750)\n",
    "\n",
    "while True:    \n",
    "    ret, img = cam_feed.read()   \n",
    "    annotated_image, preds = obj_detect.detectObjectsFromImage(input_image=img,\n",
    "                    input_type=\"array\",\n",
    "                      output_type=\"array\",\n",
    "                      display_percentage_probability=False,\n",
    "                      display_object_name=True)\n",
    "\n",
    "    cv2.imshow(\"\", annotated_image)     \n",
    "    \n",
    "    if (cv2.waitKey(1) & 0xFF == ord(\"q\")) or (cv2.waitKey(1)==27):\n",
    "        break\n",
    "      \n",
    "\n",
    "\n",
    "cam_feed.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0cba66a251407c4fd3274a4451f5ba531487019d435e911d200eb38a157ba3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
